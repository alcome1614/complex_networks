{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PageRank as Random Walk\n",
    "\n",
    "\n",
    "In graph theory theory it is important how information spreads over a graph. This is useful and used for many applications, for example detecting and predicting cyber attacks over a network or for recomendation. In this case we have seen PageRank as a way of modeling scores for nodes(or pages)that depends on scores of its neighbors. PageRank algorithm can be also interpreted as random walk process( first order Markov process), where the page rank scores are equivalent to a probability of distrition.\n",
    "\n",
    "The intuition is as following, assume we drop a pice of information how this information spreads ? wil the closest neighbors of the initial node obtain more information than others?\n",
    "\n",
    "![SegmentLocal](rw.gif \"segment\")\n",
    "\n",
    "In this interpretation we assume that we have a what in leterature is called a surfer that each time step goes from one node to the other. Particullarly the interprestation of the algorithm is ad following:\n",
    "\n",
    "01. At time $t$ the surfer is on node $i$.\n",
    "02. It anlyse all outgoing links of the current node and picks one neighbor at random called $j$\n",
    "03. At $t+1$ the surfers goes to node $j$ and repeats the process.\n",
    "\n",
    "It is ineficient tu run this process for each node so, we use the probability vector $p(t)$ where the $i$-th coordinate is the probability of the surfer to be on i-th node. Hence, the before mentioned process culd be computed as:\n",
    "\n",
    "$$\n",
    " p(t+1) = M p(t) \\text{ where $M$ is the transition matrix, same as adjacency matrix}\n",
    "$$\n",
    "\n",
    "The before formultaion is equivalent to think as following. In order to know the probability of being on node $j$-th at time $t+1$, we sum all the probabilities the random walker was on nodes that point to node $j$-th.\n",
    "\n",
    "\n",
    "<img src=\"node-pointing.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "\n",
    "Under certain characteristics of the adjacency matrix, no matter the ininitial distributin, this process converges to a stationary distribution of information (infinte time steps).\n",
    "\n",
    "In bipartite graphs the walker can run back and forth, and the solution can not stabbilize. For that reason we use lazy random walks and personalized random walks.\n",
    "\n",
    "### Lazy random walk \n",
    "\n",
    "We add a probability of $0.5$ to the surfer to stay in the current node. So the previous formula is as follwing:\n",
    "\n",
    "$$\n",
    "    p(t+1) = 0.5(M+I) p(t) \n",
    "$$\n",
    "\n",
    "The simulation can be seen as following. Where the thickness and the color of the edges are the “information current”, difference between the amount of information between nodes (the thicker the higer the information).Edges with an adjacent vertex that has a high degree tend to have more color, this vertices  ontain a significantly larger part of information .\n",
    "\n",
    "![SegmentLocal](rw-lazy.gif \"segment\")\n",
    "\n",
    "\n",
    "The distribbution converges, and it is not realted to where the information started. The converged distribution is highly related to the degree of the nodes, the more the degree the higher amount of information receives.\n",
    "\n",
    "### Personalized Random Walk\n",
    "\n",
    "The Personalized verision put the starting node as an important aspect of the algorith. It gives a probability that the random surfer jump back to inital node, the node that starts spreading information. This jump is regulated by th $\\alpha$ parameter and the restarting vector $E$. Vector $E$ selects the source (1 in the coordinates that want to be the source) node and alpha regulates the walk lenght, the higher the alpha the shorter the length of the walks originated from the source\n",
    "\n",
    "$$\n",
    "    p(t+1) = (1-\\alpha)*M p(t) + E \n",
    "$$\n",
    "\n",
    "Generally $\\alpha$ is low, in order to let the walker travel further.\n",
    "\n",
    "![SegmentLocal](rw-per.gif \"segment\")\n",
    "\n",
    "This is used in many application. For ciber security attacks, the personalized random works starts from few trusted users, distribute the \"trust\" (information spred well in high conected nodes, and not in the less connected ones) far enougph and detect the most unconected users from the source ones. For web-recomendations the source nodes are liked pages of the users, and spread information from this pages in order to recommend new ones (higher probability to web apages that are closeer to often visted pages) \n",
    "\n",
    "Follwing we apply the personalized page rank to the movies/user bipartite graph. We select a movie as source node, and propagets the information in order to determine the  nodes that receives more informetion fro the source one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "COMPLEX_NETS",
   "language": "python",
   "name": "complex_nets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
